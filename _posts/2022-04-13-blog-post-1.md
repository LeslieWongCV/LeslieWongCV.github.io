---
title: 'Bayesian Neural Network'
date: 2022-04-13
permalink: /posts/2022/4/blog-post-1/
categories:
  - Blog Posts
tags:
  - Bayesian Neural Network
location: "Singapore"
---
<div align = 'center'>
<img src='/images/bayes_mlp.png' width = "500" >
</div>

## Bayesian Neural Network

In contrast to traditional neural networks, Bayesian Neural Networks(BNN)' weights are allocated a probability distribution rather than a single value or point estimate. BNN has the following advantages:

1. Ensemble Model. Because the weights in the Bayesian neural network are allocated a probability distribution, then multiple sampling of BNN on a certain weight distribution can be integrated for prediction, which is equivalent to ensemble.  
2. Uncertainty of the prediction. Multiple sampling on a distribution would help us get the standard deviation of the prediction, which tells us the uncertainty of the prediction.
3. Regularization.

Instead of learning the weights directly, a Bayesian neural network is trained using variational inference to learn the parameters of these distributions(μ and σ when the weights are allocated a Gaussian Distribution):  

<div align = 'center'>
<img src='/images/bayes_mlp.png' width = "500" >
</div>
> Figure 3.1: Left: the weights are fixed during forward propagation. Right: each weight is assigned a distribution.  

A neural network can be considered as a probabilistic model p(y|x,w). y is
referred to a set of classes while a categorical distribution is referred to as p(y|x,w). y is a continuous variable in regression, while p(y|x,w) is a Gaussian distribution.

Given a training dataset D{$x^(i)$, $y^(i)$}. For a neural network, we could construct the likelihood function $p(D|\textbf{w}) = \prod_{i} p(y^{i} | \textbf{x}^{i}, \textbf{w})$. which is a function of parameters $\textbf{w}$. Maximizing the likelihood function gives the maximimum likelihood estimate (MLE) of $\textbf{w}$. The usual optimization objective during training is the negative log likelihood. For a categorical distribution this is the cross entropy error function, for a Gaussian distribution this is proportional to the sum of squares error function. MLE can lead to severe overfitting though.

$\theta_{MLE} &= \underset{\theta}{\operatorname{argmax}} log\  p(D|w)$
$&= \underset{\theta}{\operatorname{argmax}} \sum_{i=1}^{n} log \ p((y_{i} | x_{i} , w)$

In bayesian's view, we could add a prior $p(w)$ to the MLE:
$\theta_{MAP} &= \underset{\theta}{\operatorname{argmax}}log \ p(w|D)$
$&= \underset{\theta}{\operatorname{argmax}} log \ p(D|w) + log\ p(w) - log\ p(D)$
$&= \underset{\theta}{\operatorname{argmax}} log \ p(D|w) + log\ p(w)$

Which $log\ p(w)$ is equivalent to an L2 regularization term (which tends to be a small value).
And when the prior is a Laplace Distribution, $log\ p(w)$ is equivalent to an L1 regularization (tends to be 0 to make the weights sparse).

Both MLE and MAP give point estimates of parameters. If we instead had a full **posterior distribution** over parameters we could make predictions that take weight uncertainty into account. Then the probabilistic model would be:

$p(y|x) &= E_{p(w|D)}[p(y|x,w)]$
$&= \int_{w}^{} p(y|x, w)p(w|D)dw$  

Then there are two problems:
1. 
which the parameters have been marginalized out. This is equivalent to averaging predictions from an ensemble of neural networks weighted by the posterior probabilities of their parameters $w$.
**The frequentists view** is that the **data is a repeatable random sample** (random variable) with a specific frequency/probability. The underlying parameters and probabilities remain constant during this repeatable process and that the variation is due to variability in X<sub>n</sub> and not the probability distribution (which is fixed for a certain event/process).

Eg:
Define *P(X)* is the **probability density function(PDF)** of *X* with parameter θ. After we got a sequence of observation (X<sub>1</sub>, X<sub>2</sub>, ..., X<sub>n</sub>) = (x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>), we would like to get the estimate for parameter θ.

In frequentists view, θ has specific value. Event (X<sub>1</sub>, X<sub>2</sub>, ..., X<sub>n</sub>) = (x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>) is most likely to occur when θ = θ-MLE-, which θ<sub>MLE</sub> is the Maximum Likelihood Estimation of θ.

<div align = 'center'>
<img src='/images/Bayeisan_Fomular.png' width = "350" >
</div>

The item that needs to be optimized is Negative Log Likelihood (NLL). 

## Bayesian Estimation


**The bayesian view** is that **the data is fixed** while the frequency/probability for a certain event can change, which means the parameters of the distribution changes. In effect, the data that you get changes the prior distribution of a parameter which gets updated for each set of data. (the prior is changed when using different dataset)


<div align = 'center'>
<img src='/images/Bayesian_Formular2.png' width = "300" >
</div>

**p(θ)**: prior, which is the probability distribution that would express one's beliefs about this quantity before some evidence is taken into account.   
**p(x|θ)**: likelihood, what would x be when θ is known.  
**p(θ|x)**: posterior, the distribution of the parameter.  
**p(x)**: prior of the dataset, a constant that is independent of the parameter θ to be estimated.  

**Bayesian estimation is equivalent to that θ obeys the prior distribution p(θ), and then corrects the prior distribution according to the observed samples, and finally obtains the posterior distribution p(θ∣x), and then takes the posterior distribution Expected as an estimate of the parameter.**

Bayesian estimation equals to MLE when p(θ) is Gaussian distribution.


## Maximum a posteriori estimation  

We can calculate the posterior distribution of θ using Bayes' theorem.
**A maximum a posteriori probability (MAP) **estimate is an estimate of an unknown quantity, that equals the mode of the posterior distribution. 

<div align = 'center'>
<img src='/images/Bayesian_Formular3.png' width = "500" >
</div>

The *-logp(x∣θ)* is Negative Log Likelihood(NLL). Therefore, compared with MLE, MAP is an additional a priori term p(θ) during optimization. In some cases, −logp(θ) can be used as a regularizer in structured risk when using MLE, such as when the prior is a Gaussian distribution:

<div align = 'center'>
<img src='/images/Bayesian_Formular4.png' width = "350" >
</div>

At this time, *−logp(θ)* is equivalent to an **L2 regularization term** (which tends to be a small value).

And when the prior is a Laplace Distribution, *−logp(θ)* is equivalent to an **L1 regularization** (tends to be 0 to make the weights sparse).

MAP provides an intuitive way to design complex but interpretable regularization terms, for example more complex regularization terms can be obtained by taking mixture Gaussian distributions as priors.

## Compare

**Posterior = Likelihood * prior  
MAP = MAE * Prior**

If we toss a coin 10 times, and get 7 heads and 3 tails. MAE would tell the probability of heads is 0.7. While if MAP takes a prior of head as 0.5, the final result would be 0.5-0.7.